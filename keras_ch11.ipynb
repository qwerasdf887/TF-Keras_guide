{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sequence 與 tf.data速度比較**  \n",
    "實際測試訓練model使用兩種不同的資料載入方式進行訓練，比較差異。  \n",
    "## 實測環境  \n",
    "+ CPU: I7-9700K\n",
    "+ MB: GIGABYTE Z390 GAMING X\n",
    "+ VGA: ASUS TURBO-RTX2060S-8G-EVO\n",
    "+ RAM: 32G DDR4 3200\n",
    "+ SSD: WD SN750 500G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "import numpy as np\n",
    "import imgaug.augmenters as iaa\n",
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "flowers_root = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)\n",
    "flowers_root = pathlib.Path(flowers_root)\n",
    "\n",
    "flowers_name = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "\n",
    "images_path = []\n",
    "for dic in flowers_name:\n",
    "    for path in os.listdir(flowers_root/dic):\n",
    "        images_path.append(flowers_root/dic/path)\n",
    "\n",
    "# data augmentation API\n",
    "aug = iaa.Sequential(\n",
    "    [iaa.RandAugment(n=2, m=9),\n",
    "     iaa.Resize({'longer-side': 224, 'shorter-side': 'keep-aspect-ratio'}),\n",
    "     iaa.PadToSquare()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Sequence訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# total data \n",
    "total_data = 3670\n",
    "batch_size = 64\n",
    "\n",
    "# creat mobilenet model\n",
    "model = tf.keras.applications.MobileNetV2(weights=None, classes=5)\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=tf.keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence\n",
    "class flowers(tf.keras.utils.Sequence):\n",
    "    def __init__(self, flowers_path, batch_size):\n",
    "        self.path = flowers_path\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.path) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_path = self.path[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        \n",
    "        label = []\n",
    "        images = []\n",
    "        \n",
    "        for i in batch_path:\n",
    "            label.append(flowers_name.index(i.parent.name))\n",
    "            img = cv2.imread(str(i))\n",
    "            img = aug(image=img)\n",
    "            images.append(img)\n",
    "        \n",
    "        label = np.array(label)\n",
    "        images = np.array(images) / 255\n",
    "        return images, label\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "58/58 [==============================] - 21s 355ms/step - loss: 1.9769 - sparse_categorical_accuracy: 0.1717\n",
      "Epoch 2/5\n",
      "58/58 [==============================] - 20s 348ms/step - loss: 1.5124 - sparse_categorical_accuracy: 0.3245\n",
      "Epoch 3/5\n",
      "58/58 [==============================] - 20s 345ms/step - loss: 1.2897 - sparse_categorical_accuracy: 0.4490\n",
      "Epoch 4/5\n",
      "58/58 [==============================] - 20s 344ms/step - loss: 1.1799 - sparse_categorical_accuracy: 0.5131\n",
      "Epoch 5/5\n",
      "58/58 [==============================] - 20s 352ms/step - loss: 1.1075 - sparse_categorical_accuracy: 0.5490\n",
      "Use times:110.0877\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.fit(flowers(images_path, batch_size), epochs=5)\n",
    "print('Use times:{:4.4f}'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用tf.data訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(flowers_root/'*/*.jpg'))\n",
    "\n",
    "def get_label(name):\n",
    "    label = flowers_name.index(name.numpy().decode('UTF-8'))\n",
    "    return label\n",
    "\n",
    "def aug_img(image):\n",
    "    image = aug(image=image.numpy())\n",
    "    return image\n",
    "\n",
    "# 依照路徑資料進行處理\n",
    "def process_path(path):\n",
    "    # 取出檔名\n",
    "    name = tf.strings.split(path, os.sep)[-2]\n",
    "    # 找出對應的index\n",
    "    label = tf.py_function(get_label, [name], tf.float32)\n",
    "    # 載入圖片\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.py_function(aug_img, [image], tf.uint8)\n",
    "    # 轉換成float32以及normalize\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list_ds.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# total data \n",
    "total_data = 3670\n",
    "batch_size = 64\n",
    "\n",
    "# creat mobilenet model\n",
    "model = tf.keras.applications.MobileNetV2(weights=None, classes=5)\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=tf.keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.batch(batch_size).repeat().prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "58/58 [==============================] - 18s 304ms/step - loss: 1.4564 - sparse_categorical_accuracy: 0.3651\n",
      "Epoch 2/5\n",
      "58/58 [==============================] - 17s 299ms/step - loss: 1.2566 - sparse_categorical_accuracy: 0.4586\n",
      "Epoch 3/5\n",
      "58/58 [==============================] - 18s 304ms/step - loss: 1.2026 - sparse_categorical_accuracy: 0.5038\n",
      "Epoch 4/5\n",
      "58/58 [==============================] - 19s 321ms/step - loss: 1.1179 - sparse_categorical_accuracy: 0.5542\n",
      "Epoch 5/5\n",
      "58/58 [==============================] - 18s 303ms/step - loss: 1.0401 - sparse_categorical_accuracy: 0.5886\n",
      "Use times:94.4882\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.fit(train_data, epochs=5, steps_per_epoch=math.ceil(total_data/batch_size))\n",
    "print('Use times:{:4.4f}'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **總結**  \n",
    "雖然`Sequence`與`tf.data`都是做相同的事情，但是`tf.data`在這個實驗當中快了一點。  \n",
    "但是在另一個較舊款的電腦上，實行時間`tf.data`幾乎快了一倍，看來之後必須改用`tf.data`來提升效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
