{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras輸入資料的方法  \n",
    "使用`fit()` method輸入資料有以下幾種方法：  \n",
    "* `fit(x=train_x, y=train_y, ...)`：所有資料會載入GPU RAM中，若資料龐大，則必須使用其他方式載入。  \n",
    "* `fit(keras.utils.Sequence, ...)`：使用Python generato載入資料，可以解決無法一次將所有資料載入GPU RAM中的問題。  \n",
    "* `fit(tf.Dataset, ...)`：TensorFlow提供的載入資料方式，也可以解決資料過大的問題。  \n",
    "\n",
    "這邊主要說明`Sequence`的方式，更多資訊參閱[Training & evaluation with the built-in methods](https://keras.io/guides/training_with_built_in_methods/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "# 載入所需lib\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Sequence主要要寫`__getitme__`與`__len__`兩個method，若有需要打散data可在`on_epoch_end` method中增加打散方式。  \n",
    "以下是範例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST 手寫資料\n",
    "class MNIST_Sequence(tf.keras.utils.Sequence):\n",
    "    \n",
    "    # 初始化一些參數資料，假設輸入是圖像路徑列表，可在__getitem__中寫入讀取方式以及處理\n",
    "    # 因為使用MNIST，所以此處直接回傳批次(batch)\n",
    "    def __init__(self, x_train, y_train, batch_size):\n",
    "        self.x, self.y = x_train, y_train\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    # 計算一次疊代有多少個batch\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    \n",
    "    # 每一個batch生成的資料在這處理\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        \n",
    "        batch_x = batch_x.astype('float32') / 255\n",
    "        batch_y = batch_y.astype('float32')\n",
    "        \n",
    "        batch_x = np.expand_dims(batch_x, -1)\n",
    "        batch_y = np.expand_dims(batch_y, -1)\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    # 每個epoch結束後打亂資料\n",
    "    def on_epoch_end(self):\n",
    "        # 存放此次打散的參數\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(self.x)\n",
    "        # 還原打散前的狀態，在打散y，則打散就可以對應\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train\n",
      "shape:(60000, 28, 28),data type:uint8\n",
      "y_train\n",
      "shape:(60000,),data type:uint8\n",
      "x_test\n",
      "shape:(10000, 28, 28),data type:uint8\n",
      "y_test\n",
      "shape:(10000,),data type:uint8\n"
     ]
    }
   ],
   "source": [
    "#download MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print('x_train\\nshape:{},data type:{}'.format(x_train.shape, x_train.dtype))\n",
    "print('y_train\\nshape:{},data type:{}'.format(y_train.shape, y_train.dtype))\n",
    "print('x_test\\nshape:{},data type:{}'.format(x_test.shape, x_test.dtype))\n",
    "print('y_test\\nshape:{},data type:{}'.format(y_test.shape, y_test.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#input layer(使用Conv2D需要3維(h, w, c)，所以上方只有(28, 28)需做處理變成(28, 28, 1)\n",
    "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "# model layer\n",
    "conv_1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "max_pool_1 = tf.keras.layers.MaxPooling2D()\n",
    "conv_2 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "max_pool_2 = tf.keras.layers.MaxPooling2D()\n",
    "flatten = tf.keras.layers.Flatten()\n",
    "drop = tf.keras.layers.Dropout(0.5)\n",
    "output = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "# path\n",
    "x = conv_1(inputs)\n",
    "x = max_pool_1(x)\n",
    "x = conv_2(x)\n",
    "x = max_pool_2(x)\n",
    "x = flatten(x)\n",
    "x = drop(x)\n",
    "x = output(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3456 - sparse_categorical_accuracy: 0.8945\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1074 - sparse_categorical_accuracy: 0.9669\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9744\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9795\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9817\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9832\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9862\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0426 - sparse_categorical_accuracy: 0.9865\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0415 - sparse_categorical_accuracy: 0.9864\n"
     ]
    }
   ],
   "source": [
    "#compile model\n",
    "#sparse_categorical_crossentropy:可以直接對應數字，而不用轉換成one-hot encoding\n",
    "#有些內建的function可以直接輸入名稱帶入，不然就得放置相應的function\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "history = model.fit(MNIST_Sequence(x_train, y_train, 128), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.evaluate()`也是相同方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0262 - sparse_categorical_accuracy: 0.9905\n",
      "test loss: 0.026222582906484604\n",
      "test accuracy 0.9904999732971191\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(MNIST_Sequence(x_test, y_test, 128))\n",
    "print('test loss:', score[0])\n",
    "print('test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **總結**  \n",
    "此處演示`keras.utils.Sequence`的用法，當想使用`fit()`但是資料龐大無法放入GPU時的解決方法。  \n",
    "`__init__`、`__len__`、`__getitem__`、`on_epoch_end`，皆有不同的功能，根據需要進行修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
